{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PySparkMLib.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOx3r7ULDvqdO5irHGCtwmQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mohiteprathamesh1996/Predicting-Annual-Customer-Spending-on-E-Commerce-Websites/blob/main/PySparkMLib.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j6vNdnN-f3bB"
      },
      "source": [
        "<h2 align=\"center\"> Predicting Annual Customer Spending on E-Commerce Websites  using PySpark MLib"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y-N1yO1afhBI"
      },
      "source": [
        "#### Importing packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iKZKBmi2feIx"
      },
      "source": [
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "import pandas_datareader as pdr\r\n",
        "import datetime\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import requests\r\n",
        "import json\r\n",
        "from tqdm import tqdm\r\n",
        "import seaborn as sns\r\n",
        "import numpy.random as npr\r\n",
        "import scipy.stats as scs\r\n",
        "from scipy.stats import norm\r\n",
        "import warnings\r\n",
        "warnings.filterwarnings(\"ignore\")\r\n",
        "plt.style.use('fivethirtyeight')\r\n",
        "\r\n",
        "from sklearn.metrics import mean_squared_error, r2_score"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TxrAsh7BhZ_D"
      },
      "source": [
        "#### Create Spark session"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "id": "ZLkxWuHVhAcu",
        "outputId": "9aca03aa-9e2a-478a-b2a6-4513f5e5c0a4"
      },
      "source": [
        "# Install pyspark library\r\n",
        "!pip install pyspark\r\n",
        "\r\n",
        "# Create new Spark session\r\n",
        "from pyspark.sql import SparkSession\r\n",
        "\r\n",
        "spark = SparkSession.builder.appName(\"Customers\").getOrCreate()\r\n",
        "\r\n",
        "# Print Spark session\r\n",
        "spark"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.6/dist-packages (3.0.1)\n",
            "Requirement already satisfied: py4j==0.10.9 in /usr/local/lib/python3.6/dist-packages (from pyspark) (0.10.9)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://5e798138edc1:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.0.1</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>Customers</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ],
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7f70ce1c1fd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AInnqmQchAZu"
      },
      "source": [
        "# from pyspark.ml.regression import LinearRegression"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZAylQlQriOth"
      },
      "source": [
        "#### Load data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "FsRkSSWjhAWp",
        "outputId": "bf7c81e5-f57b-4468-c9bc-3986c7b63205"
      },
      "source": [
        "path_data_file = \"https://raw.githubusercontent.com/krishnaik06/PysparkRegressions/master/Ecommerce_Customers.csv\"\r\n",
        "\r\n",
        "df_ecommerce = pd.read_csv(path_data_file)\r\n",
        "\r\n",
        "df_ecommerce.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Email</th>\n",
              "      <th>Address</th>\n",
              "      <th>Avg Session Length</th>\n",
              "      <th>Time on App</th>\n",
              "      <th>Time on Website</th>\n",
              "      <th>Length of Membership</th>\n",
              "      <th>Yearly Amount Spent</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>mstephenson@fernandez.com</td>\n",
              "      <td>835 Frank TunnelWrightmouth, MI 82180-9605</td>\n",
              "      <td>34.497268</td>\n",
              "      <td>12.655651</td>\n",
              "      <td>39.577668</td>\n",
              "      <td>4.082621</td>\n",
              "      <td>587.951054</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>hduke@hotmail.com</td>\n",
              "      <td>4547 Archer CommonDiazchester, CA 06566-8576</td>\n",
              "      <td>31.926272</td>\n",
              "      <td>11.109461</td>\n",
              "      <td>37.268959</td>\n",
              "      <td>2.664034</td>\n",
              "      <td>392.204933</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>pallen@yahoo.com</td>\n",
              "      <td>24645 Valerie Unions Suite 582Cobbborough, DC ...</td>\n",
              "      <td>33.000915</td>\n",
              "      <td>11.330278</td>\n",
              "      <td>37.110597</td>\n",
              "      <td>4.104543</td>\n",
              "      <td>487.547505</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>riverarebecca@gmail.com</td>\n",
              "      <td>1414 David ThroughwayPort Jason, OH 22070-1220</td>\n",
              "      <td>34.305557</td>\n",
              "      <td>13.717514</td>\n",
              "      <td>36.721283</td>\n",
              "      <td>3.120179</td>\n",
              "      <td>581.852344</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>mstephens@davidson-herman.com</td>\n",
              "      <td>14023 Rodriguez PassagePort Jacobville, PR 372...</td>\n",
              "      <td>33.330673</td>\n",
              "      <td>12.795189</td>\n",
              "      <td>37.536653</td>\n",
              "      <td>4.446308</td>\n",
              "      <td>599.406092</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                           Email  ... Yearly Amount Spent\n",
              "0      mstephenson@fernandez.com  ...          587.951054\n",
              "1              hduke@hotmail.com  ...          392.204933\n",
              "2               pallen@yahoo.com  ...          487.547505\n",
              "3        riverarebecca@gmail.com  ...          581.852344\n",
              "4  mstephens@davidson-herman.com  ...          599.406092\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "92_4_3a4iwT8"
      },
      "source": [
        "#### Add pandas dataframe to Spark cluster"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j_K_BvLLhAOV",
        "outputId": "270c19a1-2e3d-47e2-8955-27bb6866b63f"
      },
      "source": [
        "# Create Spark temporary dataframe\r\n",
        "spark_df_ecommerce = spark.createDataFrame(data = df_ecommerce)\r\n",
        "\r\n",
        "# Add spark_df_ecommerce to the catalog\r\n",
        "spark_df_ecommerce.createOrReplaceTempView(name=\"spark_df_ecommerce\")\r\n",
        "\r\n",
        "# Show all tables in the Spark catalog\r\n",
        "print(\"List of tables in the Spark catalog : \\n\",spark.catalog.listTables())\r\n",
        "\r\n",
        "# Describe dataset\r\n",
        "print(\"\\n Table schema : \\n\")\r\n",
        "spark_df_ecommerce.printSchema()\r\n",
        "\r\n",
        "# Print top 5 rows of the dataset uploaded to Spark catalog\r\n",
        "print(\"\\n\")\r\n",
        "spark.table(tableName=\"spark_df_ecommerce\").show(5)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "List of tables in the Spark catalog : \n",
            " [Table(name='spark_df_ecommerce', database=None, description=None, tableType='TEMPORARY', isTemporary=True)]\n",
            "\n",
            " Table schema : \n",
            "\n",
            "root\n",
            " |-- Email: string (nullable = true)\n",
            " |-- Address: string (nullable = true)\n",
            " |-- Avg Session Length: double (nullable = true)\n",
            " |-- Time on App: double (nullable = true)\n",
            " |-- Time on Website: double (nullable = true)\n",
            " |-- Length of Membership: double (nullable = true)\n",
            " |-- Yearly Amount Spent: double (nullable = true)\n",
            "\n",
            "\n",
            "\n",
            "+--------------------+--------------------+------------------+-----------+---------------+--------------------+-------------------+\n",
            "|               Email|             Address|Avg Session Length|Time on App|Time on Website|Length of Membership|Yearly Amount Spent|\n",
            "+--------------------+--------------------+------------------+-----------+---------------+--------------------+-------------------+\n",
            "|mstephenson@ferna...|835 Frank TunnelW...|       34.49726773|12.65565115|    39.57766802|         4.082620633|         587.951054|\n",
            "|   hduke@hotmail.com|4547 Archer Commo...|       31.92627203|11.10946073|    37.26895887|         2.664034182| 392.20493339999996|\n",
            "|    pallen@yahoo.com|24645 Valerie Uni...|       33.00091476|11.33027806|    37.11059744|  4.1045432019999994|        487.5475049|\n",
            "|riverarebecca@gma...|1414 David Throug...|       34.30555663|13.71751367|    36.72128268|         3.120178783|         581.852344|\n",
            "|mstephens@davidso...|14023 Rodriguez P...|       33.33067252|12.79518855|     37.5366533|         4.446308318|         599.406092|\n",
            "+--------------------+--------------------+------------------+-----------+---------------+--------------------+-------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T1j6MB6lr2ay"
      },
      "source": [
        "#### Assembling a vector of independant feartures"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gWuegpy2mQaD"
      },
      "source": [
        "from pyspark.ml.feature import VectorAssembler\r\n",
        "\r\n",
        "fearture_assembler = VectorAssembler(inputCols = ['Avg Session Length', 'Time on App',\r\n",
        "                                                  'Time on Website', 'Length of Membership'], \r\n",
        "                                     outputCol = 'Independant_Features')\r\n",
        "\r\n",
        "dataset = fearture_assembler.transform(spark_df_ecommerce)\r\n",
        "\r\n",
        "dataset = dataset.select([\"Independant_Features\", \"Yearly Amount Spent\"])"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9j-CS7totcaQ"
      },
      "source": [
        "#### Split training and validation datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b9E-mXW3tcBw"
      },
      "source": [
        "train, val = dataset.randomSplit([0.70, 0.30])"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "60lgnyHzvJ0a"
      },
      "source": [
        "#### Fitting regressor "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ONebGkaqmQVo",
        "outputId": "36fb3f56-0d7f-4a3d-afc1-b5cba3bd2f4e"
      },
      "source": [
        "from pyspark.ml.regression import LinearRegression, DecisionTreeRegressor, RandomForestRegressor, GBTRegressor\r\n",
        "\r\n",
        "models = [(\"LinearRegressionModel\", LinearRegression),\r\n",
        "          (\"DecisionTreeRegressor\", DecisionTreeRegressor),\r\n",
        "          (\"RandomForestRegressor\", RandomForestRegressor),\r\n",
        "          (\"GBTRegressor\", GBTRegressor)]\r\n",
        "model = []\r\n",
        "rmse_score = []\r\n",
        "regr = []\r\n",
        "\r\n",
        "for m in tqdm(models):\r\n",
        "  regressor = m[1](featuresCol=\"Independant_Features\", labelCol=\"Yearly Amount Spent\").fit(dataset = train)\r\n",
        "\r\n",
        "  results = regressor.transform(val).toPandas()\r\n",
        "\r\n",
        "  rmse_score.append(np.sqrt(mean_squared_error(results[\"Yearly Amount Spent\"], \r\n",
        "                                               results[\"prediction\"])))\r\n",
        "  \r\n",
        "  model.append(m[0])\r\n",
        "  regr.append(m[1])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:25<00:00,  6.38s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PdbZsqBm_3_4"
      },
      "source": [
        "#### Comparing model performance leaderboard"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        },
        "id": "ah7LfsLgljZi",
        "outputId": "8df2db7b-f41c-4e79-a86b-5b130960b863"
      },
      "source": [
        "pd.DataFrame([model, rmse_score, regr], index=[\"Model Fitted\", \"Root Mean Squared Error\", \"To_Save\"]).T"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model Fitted</th>\n",
              "      <th>Root Mean Squared Error</th>\n",
              "      <th>To_Save</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>LinearRegressionModel</td>\n",
              "      <td>9.93691</td>\n",
              "      <td>&lt;class 'pyspark.ml.regression.LinearRegression'&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>DecisionTreeRegressor</td>\n",
              "      <td>34.4644</td>\n",
              "      <td>&lt;class 'pyspark.ml.regression.DecisionTreeRegr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>RandomForestRegressor</td>\n",
              "      <td>30.5318</td>\n",
              "      <td>&lt;class 'pyspark.ml.regression.RandomForestRegr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>GBTRegressor</td>\n",
              "      <td>27.1546</td>\n",
              "      <td>&lt;class 'pyspark.ml.regression.GBTRegressor'&gt;</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            Model Fitted  ...                                            To_Save\n",
              "0  LinearRegressionModel  ...   <class 'pyspark.ml.regression.LinearRegression'>\n",
              "1  DecisionTreeRegressor  ...  <class 'pyspark.ml.regression.DecisionTreeRegr...\n",
              "2  RandomForestRegressor  ...  <class 'pyspark.ml.regression.RandomForestRegr...\n",
              "3           GBTRegressor  ...       <class 'pyspark.ml.regression.GBTRegressor'>\n",
              "\n",
              "[4 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cGpQfmC-ffkO"
      },
      "source": [
        ""
      ],
      "execution_count": 9,
      "outputs": []
    }
  ]
}